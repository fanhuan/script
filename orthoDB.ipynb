{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all protein sequences in orthoDB v11 for one/multiple species\n",
    "\n",
    "1. odb11v0_OG2genes.tab.gz were downloaded from https://data.orthodb.org/download/\n",
    "wget https://data.orthodb.org/download/odb11v0_OG2genes.tab.gz\n",
    "2. get the OG ids that are related to oil palm (taxid 51953)\n",
    "zcat odb11v0_OG2genes.tab.gz | grep 51953_0 | cut -f 1 | sort | uniq > OG_51953_0.tab\n",
    "3. Download the oil palm protein sequences from the clusters that contains oil palm sequences\n",
    "nohup sh download.sh > logfile 2>&1 < /dev/null &\n",
    "\n",
    "download.sh:\n",
    "#!/bin/bash\n",
    "output_file=\"combined_data.tsv\"\n",
    "\n",
    "while IFS= read -r line; do\n",
    "    curl \"https://data.orthodb.org/current/fasta?id=$line&species=51953\" -L -k >> \"$output_file\"\n",
    "done < \"OG_51953_0.tab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl 'https://data.orthodb.org/current/blast?seq=MGQMGGPDGDGPHHQYHYQALLAAVQNPSQGLHVPLHAGAGAPAAGPGPRPGADADASSTHNANATPHSQPPRAFTDWSASNSAFAAQPAPATTNTPFHYNLSQSYALWTHYMLNKNVSYSTYSTPHEPLRHTHIPDKYSGCAFSLGFDSFTTMSLGPNICANMTPMERSISAKEPENSEDLPTVVRSSDEMDTRNSGDVRRDTVDTLPESKQSHESCASVSNKFDSGEYQVILRKELTKSDVANSGRIVLPKKDAEAGLPPLVQGDPLILQMDDMVLPIIWKFKYRFWPNNKSRMYILEAAGEFVKTHGPSGRGYAHYLQKLRTWQIYYPWGEVHSADNP' -L -o blast.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2368    0  2368    0     0   1121      0 --:--:--  0:00:02 --:--:--  1122\n"
     ]
    }
   ],
   "source": [
    "!curl 'https://data.orthodb.org/current/blast?seq=MGQMGGPDGDGPHHQYHYQALLAAVQNPSQGLHVPLHAGAGAPAAGPGPRPGADADASSTHNANATPHSQPPRAFTDWSASNSAFAAQPAPATTNTPFHYNLSQSYALWTHYMLNKNVSYSTYSTPHEPLRHTHIPDKYSGCAFSLGFDSFTTMSLGPNICANMTPMERSISAKEPENSEDLPTVVRSSDEMDTRNSGDVRRDTVDTLPESKQSHESCASVSNKFDSGEYQVILRKELTKSDVANSGRIVLPKKDAEAGLPPLVQGDPLILQMDDMVLPIIWKFKYRFWPNNKSRMYILEAAGEFVKTHGPSGRGYAHYLQKLRTWQIYYPWGEVHSADNP' -L -o blast.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huan/GitHub/script\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse the search.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"/bioinfo/palm/ref/orthoDBv11/search.dat\"\n",
    "\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    data_dict = json.load(json_file)\n",
    "\n",
    "ortholog_path = \"/bioinfo/palm/ref/orthoDBv11/orthologs.dat\"\n",
    "\n",
    "with open(ortholog_path, \"r\") as json_file:\n",
    "    ortholog_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse the downloaded protein sequence to remove the redundent ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import json\n",
    "\n",
    "sequence_dic = {}\n",
    "tag_dic = {}\n",
    "level_dic = {}\n",
    "with open('/bioinfo/palm/ref/orthoDBv11/oil_palm_protein.fa','w') as fh:\n",
    "    for record in SeqIO.parse('/bioinfo/palm/ref/orthoDBv11/combined_data.tsv','fasta'):\n",
    "        if record.id in sequence_dic:\n",
    "            # gene already wrote out, check whether the sequence is different\n",
    "            if record.seq != sequence_dic[record.id]:\n",
    "                # need to write to fh if the sequence is different\n",
    "                gene, description = record.description.split(' ', 1)\n",
    "                description = description.strip()\n",
    "                description_dict = json.loads(description)\n",
    "                cluster = description_dict['pub_og_id']\n",
    "                record.id = record.id + '_' + cluster\n",
    "                tag_dic[gene] = cluster\n",
    "                SeqIO.write(record, fh, 'fasta')\n",
    "                print(gene) #nothing was printed, which means the protein sequences always stay the same no matter the node\n",
    "        else:\n",
    "            SeqIO.write(record, fh, 'fasta')\n",
    "        sequence_dic[record.id] = record.seq\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now A simpler code with the understanding that the protein sequences always stay the same for the same gene no matter the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import json\n",
    "\n",
    "sequence_dic = {}\n",
    "level_dic = {}\n",
    "with open('/bioinfo/palm/ref/orthoDBv11/oil_palm_protein.fa','w') as fh:\n",
    "    for record in SeqIO.parse('/bioinfo/palm/ref/orthoDBv11/combined_data.tsv','fasta'):\n",
    "        gene, description = record.description.split(' ', 1)\n",
    "        description = description.strip()\n",
    "        description_dict = json.loads(description)\n",
    "        cluster = description_dict['pub_og_id']\n",
    "        level = cluster.split('at')[1]\n",
    "        if level in level_dic:\n",
    "            level_dic[level].append(gene)\n",
    "        else:\n",
    "            level_dic[level] = [gene]\n",
    "        if record.id not in sequence_dic:\n",
    "            SeqIO.write(record, fh, 'fasta')\n",
    "            sequence_dic[record.id] = record.seq\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2759': 25657, '33090': 25541, '3193': 25459, '4447': 24754}\n"
     ]
    }
   ],
   "source": [
    "lengths_dict = {}\n",
    "\n",
    "# Iterate through the dictionary values and calculate lengths\n",
    "for key, value in level_dic.items():\n",
    "    unique_items = set(value)  # Create a set to store unique items\n",
    "    lengths_dict[key] = len(unique_items)\n",
    "\n",
    "print(lengths_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This means one gene is classified into only one cluster at most at one level. \n",
    "\n",
    "# Then we used orthomapper to map all dura proteins to orthodb v11. Results are in /bioinfo/tools/orthologer/Results\n",
    "\n",
    "# Now let's get the protein sequences that wasn't placed to any orthodb clusters (14632).\n",
    "\n",
    "# Note that if a gene was not placed in orthoDBv11 by othomapper, it won't be found in the reciprocal mapping between dura and EG5inOrthoDBv11 either. \n",
    "\n",
    "# Now what do we do? Map to EG5 just to see what they could have done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14632\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "file_path = 'dura.og.annotations'\n",
    "df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "df.rename(columns={'#query': 'query'}, inplace=True)\n",
    "df_eg5 = pd.read_csv('dura_EG5_orthoDB11.tbl', sep='\\t', header=None)\n",
    "i = 0\n",
    "with open('dura_proteins_not_in_orthodbv11.fasta','w') as fh:\n",
    "    for record in SeqIO.parse('../dura/dura_proteins.fasta','fasta'):\n",
    "        if record.id not in df['query'].values:\n",
    "            if record.id in df_eg5[0]:\n",
    "                print(record.id)\n",
    "            SeqIO.write(record, fh, 'fasta')\n",
    "            i += 1\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the orthomapper results from all three levels, with priority to lower levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "file1 = 'dura4447_Results/dura4447.og.annotations'\n",
    "df1 = pd.read_csv(file1, sep='\\t', header=0)\n",
    "df1.rename(columns={'#query': 'query'}, inplace=True)\n",
    "\n",
    "file2 = 'dura3193_Results/dura3193.og.annotations'\n",
    "df2 = pd.read_csv(file2, sep='\\t', header=0)\n",
    "df2.rename(columns={'#query': 'query'}, inplace=True)\n",
    "\n",
    "df2_new = df2[~df2['query'].isin(df1['query'])]\n",
    "df12 = pd.concat([df1, df2_new], ignore_index=True)\n",
    "\n",
    "file3 = 'dura33090_Results/dura33090.og.annotations'\n",
    "df3 = pd.read_csv(file3, sep='\\t', header=0)\n",
    "df3.rename(columns={'#query': 'query'}, inplace=True)\n",
    "\n",
    "df3_new = df3[~df3['query'].isin(df12['query'])]\n",
    "df123 = pd.concat([df12, df3_new], ignore_index=True)\n",
    "\n",
    "df123.to_csv('dura_orthoDBv11_4447_3193_33090.og.annotations', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to go from gene name to clusterID, then dura gene ID.\n",
    "Play with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl 'https://data.orthodb.org/current/search?query=ABI5&level=4447' -L -o ABI5_at4447.dat\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import subprocess, json\n",
    "\n",
    "gene_name = 'ABI5'\n",
    "level = 4447\n",
    "cmd = \"curl 'https://data.orthodb.org/current/search?query={}&level={}' -L -o {}_at{}.dat\".format(gene_name, level, gene_name, level)\n",
    "print(cmd)\n",
    "subprocess.run(cmd, shell=True, check=True)\n",
    "with open(\"{}_at{}.dat\".format(gene_name, level), \"r\") as json_file:\n",
    "    data_dict = json.load(json_file)\n",
    "anno_file = 'dura_orthoDBv11_4447_3193_33090.og.annotations'\n",
    "df = pd.read_csv(anno_file, sep='\\t', header=0)\n",
    "selected_rows = df[df['ODB_OG'].isin(data_dict['data'])]\n",
    "selected_rows.rename(columns={'#query': 'query'}, inplace=True)\n",
    "i = 0\n",
    "protein_file = '/bioinfo/palm/ref/dura/dura_proteins.fasta'\n",
    "with open('dura_proteins_{}_at{}.aa'.format(gene_name, level),'w') as fh:\n",
    "    for record in SeqIO.parse(protein_file,'fasta'):\n",
    "        if record.id in selected_rows['query'].values:\n",
    "            cluster = selected_rows.loc[selected_rows['query'] == record.id, 'ODB_OG']\n",
    "            tag = selected_rows.loc[selected_rows['query'] == record.id, 'Description']\n",
    "            if len(tag) == 1:\n",
    "                record.description = ':'.join([cluster.iloc[0], tag.iloc[0]])\n",
    "            else:\n",
    "                print(record.id + 'appeared in more than one cluster?')\n",
    "\n",
    "            SeqIO.write(record, fh, 'fasta')\n",
    "            i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_rows.loc[selected_rows['query'] == 'Egu023084-mRNA-1', 'ODB_OG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We ran orthoDB on four other species and compared them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "level = 4447\n",
    "def og_dic(level, name):\n",
    "    # this function takes a orthoDB annotation, count the cluser compotion and return a pd\n",
    "    anno_file = \"/bioinfo2/palm/ref/orthoDBv11/{}_{}.og.annotations\".format(name, level)\n",
    "    df = pd.read_csv(anno_file, sep='\\t', header=0)\n",
    "    dic = Counter(df['ODB_OG'])\n",
    "    # Convert dictionaries to DataFrames\n",
    "    df = pd.DataFrame(list(dic.items()), columns=['key', name]).set_index('key')\n",
    "    return(df)\n",
    "\n",
    "df_dura = og_dic(4447, 'dura')\n",
    "df_coco = og_dic(4447, 'coco')\n",
    "df_date = og_dic(4447, 'date')\n",
    "df_picifera = og_dic(4447, 'EG5')\n",
    "df_rice = og_dic(4447, 'rice')\n",
    "\n",
    "df = pd.concat([df_dura, df_coco, df_date, df_picifera, df_rice], axis=1)\n",
    "\n",
    "df.to_csv(\"/bioinfo2/palm/ref/orthoDBv11/combined_og.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dura</th>\n",
       "      <th>coco</th>\n",
       "      <th>date</th>\n",
       "      <th>EG5</th>\n",
       "      <th>rice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6at4447</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12at4447</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20at4447</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40at4447</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71at4447</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160426at4447</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160446at4447</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160453at4447</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160476at4447</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160483at4447</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24041 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dura  coco  date  EG5  rice\n",
       "key                                      \n",
       "6at4447        1.0   1.0   1.0  1.0   1.0\n",
       "12at4447       1.0   1.0   3.0  3.0   2.0\n",
       "20at4447       2.0   1.0   4.0  3.0   1.0\n",
       "40at4447       2.0   1.0   3.0  3.0   2.0\n",
       "71at4447       2.0   1.0   5.0  3.0   1.0\n",
       "...            ...   ...   ...  ...   ...\n",
       "160426at4447   NaN   NaN   NaN  NaN   7.0\n",
       "160446at4447   NaN   NaN   NaN  NaN   1.0\n",
       "160453at4447   NaN   NaN   NaN  NaN   1.0\n",
       "160476at4447   NaN   NaN   NaN  NaN   1.0\n",
       "160483at4447   NaN   NaN   NaN  NaN   2.0\n",
       "\n",
       "[24041 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df123[df123.duplicated('query')]  # Replace 'column_name' with the actual column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "anno_file = 'dura_orthoDBv11_4447_3193_33090.og.annotations'\n",
    "df = pd.read_csv(anno_file, sep='\\t', header=0)\n",
    "tpm_file = 'counts_transcript_TPM_concise.txt'\n",
    "tpm = pd.read_csv(tpm_file, sep=',', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[['query','Description']]\n",
    "df_2 = pd.merge(df_1, tpm, on='query',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
